{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    \"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\",\n",
    "    \"are\",\"aren't\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\n",
    "    \"between\",\"both\",\"but\",\"by\",\"can't\",\"cannot\",\"could\",\"couldn't\",\"did\",\n",
    "    \"didn't\",\"do\",\"does\",\"doesn't\",\"doing\",\"don't\",\"down\",\"during\",\"each\",\n",
    "    \"few\",\"for\",\"from\",\"further\",\"had\",\"hadn't\",\"has\",\"hasn't\",\"have\",\"haven't\",\n",
    "    \"having\",\"he\",\"he'd\",\"he'll\",\"he's\",\"her\",\"here\",\"here's\",\"hers\",\"herself\",\n",
    "    \"him\",\"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\n",
    "    \"into\",\"is\",\"isn't\",\"it\",\"it's\",\"its\",\"itself\",\"let's\",\"me\",\"more\",\"most\",\n",
    "    \"mustn't\",\"my\",\"myself\",\"no\",\"nor\",\"not\",\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\n",
    "    \"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"same\",\"shan't\",\n",
    "    \"she\",\"she'd\",\"she'll\",\"she's\",\"should\",\"shouldn't\",\"so\",\"some\",\"such\",\n",
    "    \"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\n",
    "    \"there\",\"there's\",\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\n",
    "    \"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\n",
    "    \"wasn't\",\"we\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"were\",\"weren't\",\"what\",\n",
    "    \"what's\",\"when\",\"when's\",\"where\",\"where's\",\"which\",\"while\",\"who\",\"who's\",\n",
    "    \"whom\",\"why\",\"why's\",\"with\",\"won't\",\"would\",\"wouldn't\",\"you\",\"you'd\",\n",
    "    \"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"Subject\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_labels():\n",
    "    _labels = {}\n",
    "    with open('./data/email/train_label.txt') as _fp:\n",
    "        for _line in _fp.readlines():\n",
    "            arr = _line.strip().split(' ')\n",
    "            _labels[arr[1]] = arr[0]\n",
    "#     test_files = random.sample(list(labels.keys()), 500)\n",
    "    return _labels\n",
    "\n",
    "\n",
    "def email_to_list(text, _stop_words):\n",
    "    _words = re.findall('[a-zA-Z\\d]{2,}', text)\n",
    "    _word_set = []\n",
    "    for w in _words:\n",
    "        if w in _stop_words or re.search('\\d', w):\n",
    "            continue\n",
    "        _word_set.append(w.lower())\n",
    "    _word_set = list(set(_word_set))\n",
    "    \n",
    "    return _word_set\n",
    "    \n",
    "    \n",
    "def load_data_set():\n",
    "    _emails = {}\n",
    "    for _fn in  os.listdir('./data/email/train/'):\n",
    "        if _fn == '.DS_Store':\n",
    "            continue\n",
    "        \n",
    "        ec = chardet.detect(open('./data/email/train/%s' % _fn, \"rb\").read())['encoding']\n",
    "        _fp = open('./data/email/train/%s' % _fn, 'r', encoding=ec)\n",
    "        \n",
    "        _emails[_fn] = email_to_list(_fp.read(), stop_words)\n",
    "                    \n",
    "    return _emails\n",
    "\n",
    "labels = load_labels()\n",
    "emails = load_data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trian num: 4027; spam num: 1280.0; ham num: 2747.0\n",
      "test num: 300; spam num: 98; ham num: 202\n",
      "error spam count: 0; error ham count: 32\n",
      "error count: 32; error rate: 0.11\n"
     ]
    }
   ],
   "source": [
    "test_files = random.sample(list(labels.keys()), 300)\n",
    "\n",
    "spam_count = 0.0; ham_count = 0.0\n",
    "word_spam_count = {}; word_ham_count = {}\n",
    "test_spam_count = 0; test_ham_count = 0\n",
    "\n",
    "for fn in emails:\n",
    "    if fn in test_files:\n",
    "        if int(labels[fn]) == 0:\n",
    "            test_spam_count += 1\n",
    "        elif int(labels[fn]) == 1:\n",
    "            test_ham_count += 1\n",
    "        continue\n",
    "        \n",
    "    if int(labels[fn]) == 0:\n",
    "        spam_count += 1\n",
    "        for w in emails[fn]:\n",
    "            word_spam_count[w] = word_spam_count.get(w, 0) + 1\n",
    "    elif int(labels[fn]) == 1:\n",
    "        ham_count += 1\n",
    "        for w in emails[fn]:\n",
    "            word_ham_count[w] = word_ham_count.get(w, 0) + 1\n",
    "            \n",
    "print('trian num: %s; spam num: %s; ham num: %s' % (len(labels) - 300, spam_count, ham_count))\n",
    "print('test num: 300; spam num: %s; ham num: %s' % (test_spam_count, test_ham_count))\n",
    "          \n",
    "p_y = float(spam_count) / float(ham_count + spam_count)\n",
    "\n",
    "err_count = 0\n",
    "err_count_spam = 0\n",
    "err_count_ham = 0\n",
    "for fn in test_files:\n",
    "    ec = chardet.detect(open('./data/email/train/%s' % fn, \"rb\").read())['encoding']\n",
    "    fp = open('./data/email/train/%s' % fn, 'r', encoding=ec)\n",
    "    cur_word_set = email_to_list(fp.read(), stop_words)\n",
    "    \n",
    "    p_y0 = p_y; p_y1 = 1.0 - p_y\n",
    "#     rate = p_y1 / p_y0\n",
    "    for w in cur_word_set:\n",
    "        p_xi_y0 = (word_spam_count.get(w, 0.0) + 1.0) / (spam_count + 2.0)\n",
    "        p_xi_y1 = (word_ham_count.get(w, 0.0) + 1.0) / (ham_count + 2.0)\n",
    "        \n",
    "        p_y1 *= p_xi_y1\n",
    "        p_y0 *= p_xi_y0\n",
    "        \n",
    "        if p_y0 < 1e-320 or p_y1 < 1e-320:\n",
    "            p_y1 *= 1e3\n",
    "            p_y0 *= 1e3\n",
    "        \n",
    "#         rate *= p_xi_y1 / p_xi_y0\n",
    "#         print(p_y1, p_y0)\n",
    "    rs = p_y0 / (p_y0 + p_y1)\n",
    "    if p_y0 == float('inf'):\n",
    "        rs = 1.0\n",
    "    \n",
    "    if rs > 0.9:\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "        \n",
    "    if int(labels[fn]) != label:\n",
    "        err_count += 1\n",
    "        if int(labels[fn]) == 0:\n",
    "            err_count_spam += 1\n",
    "        elif int(labels[fn]) == 1:\n",
    "            err_count_ham += 1\n",
    "#         print(fn, int(labels[fn]), '%.5f' % rs)\n",
    "\n",
    "print('error spam count: %s; error ham count: %s' % (err_count_spam, err_count_ham))\n",
    "print('error count: %s; error rate: %.2f' % (err_count, float(err_count)/300))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
